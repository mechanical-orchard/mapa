package com.mechanicalorchard

import CatchableErrorListener
import JCLLexer
import JCLPPLexer
import JCLPPParser
import JCLParser
import Job
import JobListener
import PPJob
import PPListener
import PPProc
import PPSetSymbolValue
import Proc
import StdoutLexerErrorListener
import TheCLI
import TreeUtils
import org.antlr.v4.runtime.*
import org.antlr.v4.runtime.misc.ParseCancellationException
import org.antlr.v4.runtime.tree.ParseTreeWalker
import java.io.*
import java.nio.file.Files
import java.nio.file.Path
import java.nio.file.Paths
import java.time.LocalDateTime
import java.time.format.DateTimeFormatter
import java.util.*
import java.util.logging.*
import kotlin.system.exitProcess

/**
 * This is intended to demonstrate use of the JCL lexing and parsing code
 * generated by the JCL*.g4 files in the ./src directory.
 *
 */
val LOGGER: Logger = Logger.getLogger("JCLParser")

@Throws(Exception::class)
fun main(args: Array<String>) {

    val df: DateTimeFormatter = DateTimeFormatter.ofPattern("yyyyMMddHHmmssSSS")
    val dateTimeStamp: String = LocalDateTime.now().format(df).toString()

    System.setProperty("java.util.logging.SimpleFormatter.format", "[%1\$tc] %4\$s: %5\$s%n")

    try {
        LOGGER.addHandler(StreamHandler(System.out, SimpleFormatter()))
        LOGGER.level = Level.ALL
        LOGGER.info("Logger Name: " + LOGGER.name)
    } catch (e: Exception) {
        LOGGER.severe("Exception $e encountered")
        e.printStackTrace()
        exitProcess(16)
    }

    val theCLI = TheCLI(args)

    val baseDir = newTempDir(theCLI) // keep all temp files contained here
    var outTree: BufferedWriter? = null
    var outCSV: BufferedWriter? = null

    if (theCLI.outtreeFileName != null) {
        outTree = BufferedWriter(FileWriter(theCLI.outtreeFileName))
    }

    if (theCLI.outcsvFileName != null) {
        outCSV = BufferedWriter(FileWriter(theCLI.outcsvFileName))
    }

    theCLI.fileNamesToProcess.forEachIndexed { index, aFileName ->
        LOGGER.info("Processing file $aFileName")
        var first = true
        val procsPP: ArrayList<PPProc> = ArrayList()
        val jobsPP: ArrayList<PPJob> = ArrayList()
        val uuid: UUID = UUID.randomUUID() //identify a file
        val aFileRewritten = rewriteWithoutCol72to80(aFileName, baseDir, theCLI)
        lexAndParsePP(jobsPP, procsPP, aFileRewritten.path, index, baseDir, theCLI)
        if (jobsPP.size == 0 && procsPP.size == 0) {
            LOGGER.info("$aFileName contains neither jobs nor procs - not JCL?")
        }
        LOGGER.fine(
            "after lexAndParsePP jobs = |"
                    + jobsPP
                    + "| procs = |"
                    + procsPP
                    + "|"
        )
        jobsPP.forEach { j ->
            LOGGER.info("Processing job " + j.jobName)
            j.resolveParmedIncludes()
            val jobFile: File = j.rewriteJobAndSeparateInstreamProcs()
            /*
                Now must iteratively parse this job until all INCLUDEs
                are resolved.  Unresolvable INCLUDEs generate a warning.
            */
            val rJob: PPJob = j.iterativelyResolveIncludes(jobFile)
            /*
                Now must rewrite job with resolved values for parms substituted.
            */
            val finalJobFile: File = rJob.rewriteWithParmsResolved()
            rJob.resolveProcs()
            /*
                Now transition from preprocessing to lexing/parsing resolved JCL.
            */
            val procs: ArrayList<Proc> = ArrayList()
            val jobs: ArrayList<Job> = ArrayList()
            lexAndParse(jobs, procs, aFileName, finalJobFile.path, index, theCLI)
            if (jobs.size == 0) {
                /*
                There was an error in parsing, possibly the input was correct
                enough to pass preprocessing but not correct enough to pass
                more rigourous processing.
                */
                LOGGER.info("Ignoring content of $aFileName due to parsing error")
                return
            }
            jobs[0].setTmpDirs(baseDir, rJob.jobDir, rJob.procDir)
            jobs[0].setOrdNb(rJob.ordNb)
            jobs[0].lexAndParseProcs()
            jobs[0].processSYSTSIN()
            if (theCLI.outtreeFileName != null) {
                val sb = StringBuffer()
                sb.append(System.lineSeparator())
                jobs[0].toTree(sb)
                outTree?.write(sb.toString())
                LOGGER.fine(sb.toString())
            }
            if (theCLI.outcsvFileName != null) {
                val buf = StringBuffer()
                buf.append(System.lineSeparator())
                buf.append("FILE")
                buf.append(",")
                buf.append(aFileName)
                buf.append(",")
                buf.append(dateTimeStamp)
                buf.append(",")
                buf.append(uuid.toString())
                buf.append(System.lineSeparator())
                jobs[0].toCSV(buf, uuid)
                outCSV?.write(buf.toString())
                LOGGER.fine(buf.toString())
            }
        }
        for (p in procsPP) {
            LOGGER.info("Processing proc " + p.procName)
            val procFile = File(p.fileName)
            /*
            Now must iteratively parse this proc until all INCLUDEs
            are resolved.  Unresolvable INCLUDEs generate a warning.
        */
            val emptySetSym: ArrayList<PPSetSymbolValue> = ArrayList()
            val rProc: PPProc = p.iterativelyResolveIncludes(emptySetSym, procFile)
            /*
            Symbolic parms may have had values SET inside an INCLUDE,
            so only now the INCLUDEs have been resolved can the symbolics
            be resolved.
        */
            rProc.resolveParms(emptySetSym)
            /*
            Now must rewrite proc with resolved values for parms substituted.
        */
            val finalProcFile: File = rProc.rewriteWithParmsResolved()
            rProc.resolveProcs()
            /*
            Now transition from preprocessing to lexing/parsing resolved JCL.
        */
            val procs: ArrayList<Proc> = ArrayList()
            val jobs: ArrayList<Job> = ArrayList()
            // we added an outdir for pushing out
            lexAndParse(jobs, procs, aFileName, finalProcFile.path, index, theCLI)
            if (procs.size == 0) {
                /*
            There was an error in parsing, possibly the input was correct
            enough to pass preprocessing but not correct enough to pass
            more rigourous processing.
            */
                LOGGER.info("Ignoring content of $aFileName due to parsing error")
                continue
            }
            procs[0].setTmpDirs(baseDir, rProc.procDir)
            procs[0].setOrdNb(rProc.ordNb)
            procs[0].lexAndParseProcs()
            if (theCLI.outtreeFileName != null) {
                val sb = StringBuffer()
                sb.append(System.lineSeparator())
                procs[0].toTree(sb)
                outTree?.write(sb.toString())
                LOGGER.fine(sb.toString())
            }
            if (theCLI.outcsvFileName != null) {
                val buf = StringBuffer()
                if (first) {
                    buf.append(System.lineSeparator())
                    buf.append("FILE")
                    buf.append(",")
                    buf.append(aFileName)
                    buf.append(",")
                    buf.append(uuid.toString())
                }
                buf.append(System.lineSeparator())
                procs[0].toCSV(buf, uuid)
                outCSV?.write(buf.toString())
                LOGGER.fine(buf.toString())
            }
            first = false
        }
    }

    if (outTree != null) {
        outTree.flush()
        outTree.close()
    }

    if (outCSV != null) {
        outCSV.flush()
        outCSV.close()
    }

    LOGGER.info("Processing complete")
}

/**
 * Parse the incoming JCL for purposes of preprocessing, which means
 * instream procs will be separated, INCLUDEs will be incorporated,
 * and symbolics will be substituted.
 *
 *
 * That preprocessing is everything that happens between the
 * first execution of this method and the first execution of the
 * lexAndParse method.
 */
@Throws(IOException::class)
fun lexAndParsePP(
    jobs: ArrayList<PPJob>,
    procs: ArrayList<PPProc>,
    fileName: String,
    fileNb: Int,
    baseDir: File?,
    theCLI: TheCLI
) {
    LOGGER.fine(
        "lexAndParsePP jobs = |"
                + jobs
                + "| procs = |"
                + procs
                + "| fileName = |"
                + fileName
                + "|"
    )

    val cs: CharStream = CharStreams.fromFileName(fileName) //load the file
    JCLPPLexer.ckCol72 = false
    val lexer = JCLPPLexer(cs) //instantiate a lexer
    lexer.removeErrorListeners()
    lexer.addErrorListener(StdoutLexerErrorListener())
    val tokens = CommonTokenStream(lexer) //scan stream for tokens

    val parser = JCLPPParser(tokens) //parse the tokens
    parser.removeErrorListeners()

    /*
    parser.addErrorListener(new StdoutParserErrorListener());
    ParseTree tree = parser.startRule(); // parse the content and get the tree
    */
    parser.addErrorListener(CatchableErrorListener())

//    var tree: ParseTree? = null
    try {
        val tree = parser.startRule() // parse the content and get the tree
        val walker = ParseTreeWalker()

        val listener = PPListener(jobs, procs, fileName, fileNb, baseDir, null, null, LOGGER, theCLI)

        LOGGER.finer("----------walking tree with " + listener.javaClass)
        walker.walk(listener, tree)
    } catch (e: ParseCancellationException) {
        LOGGER.warning("Parser error $e")
        return
    }
}

/**
 * Return a collection of tokens placed on the COMMENTS channel
 * by the lexer.  Note that this is an example of how the output
 * from the lexer can be useful on its own.
 */
@Throws(IOException::class)
fun lex(
    fileName: String
): ArrayList<Token> {
    LOGGER.fine("lex fileName = |$fileName|")

    val cs: CharStream = CharStreams.fromFileName(fileName) //load the file
    JCLPPLexer.ckCol72 = true
    val lexer = JCLPPLexer(cs) //instantiate a lexer
    lexer.removeErrorListeners()
    lexer.addErrorListener(StdoutLexerErrorListener())
    val cmtokens = CommonTokenStream(lexer, JCLPPLexer.COMMENTS) //scan stream for tokens
    val tokens: ArrayList<Token> = ArrayList()
    while (cmtokens.LA(1) != CommonTokenStream.EOF) {
        if (cmtokens.LT(1).type == JCLPPLexer.COL_72 || cmtokens.LT(1)
                .type == JCLPPLexer.COMMENT_TEXT || cmtokens.LT(1).type == JCLPPLexer.COMMENT_FLAG
        ) {
            tokens.add(cmtokens.LT(1))
        }
        cmtokens.consume()
    }
    for (t in tokens) {
        LOGGER.fine("\ttoken |${t.text}${"| @ "}${t.charPositionInLine} on ${t.line} of type ${t.type}")
    }

    return tokens
}

/**
 * Parse the JCL which has now had procs, INCLUDEs, and symbolics
 * resolved into objects which are hopefully useful for analysis.
 */
@Throws(IOException::class)
fun lexAndParse(
    jobs: ArrayList<Job>,
    procs: ArrayList<Proc>,
    originalFilePath: String,
    fileName: String,
    fileNb: Int,
    theCLI: TheCLI
) {
    LOGGER.fine("lexAndParse jobs = |$jobs| procs = |$procs| fileName = |$fileName|")

    val cs: CharStream = CharStreams.fromFileName(fileName) //load the file
    val lexer = JCLLexer(cs) //instantiate a lexer
    lexer.removeErrorListeners()
    lexer.addErrorListener(StdoutLexerErrorListener())
    val tokens = CommonTokenStream(lexer) //scan stream for tokens
    val parser = JCLParser(tokens) //parse the tokens
    parser.removeErrorListeners()

    /*
    parser.addErrorListener(new StdoutParserErrorListener());
    ParseTree tree = parser.startRule(); // parse the content and get the tree
    */
    parser.addErrorListener(CatchableErrorListener())

    try {
        val tree = parser.startRule() // parse the content and get the tree


        val walker = ParseTreeWalker()

        val listener = JobListener(jobs, procs, fileName, fileNb, LOGGER, theCLI)

        LOGGER.finer("----------walking tree with " + listener.javaClass)

        walker.walk(listener, tree)

        val originalFileName: String = Paths.get(originalFilePath).fileName.toString()
        val filePath: Path = Paths.get(theCLI.outDir, "$originalFileName.tree.tsv")
        val ruleNamesList = parser.ruleNames
        val prettyTree: String = TreeUtils.toPrettyTree(tree, ruleNamesList.asList())
        val writer = BufferedWriter(FileWriter(filePath.toString()))
        writer.write(prettyTree)
        writer.close()
        LOGGER.info("----------output tree file to $filePath")
    } catch (e: Exception) {
        LOGGER.warning("Parser error $e")
        return
    }
}

/**
 * This method rewrites a file without the troublesome columns 72
 * through 80.
 */
@Throws(IOException::class)
private fun rewriteWithoutCol72to80(aFileName: String, baseDir: File, theCLI: TheCLI): File {
    Demo01.LOGGER.finer(
        "Demo01"
                + " rewriteWithoutCol72to80"
    )

    val tokens = Demo01.lex(aFileName)
    val aFile = File(aFileName)
    val src = LineNumberReader(FileReader(aFile))
    val tmp = File(
        (baseDir.toString()
                + File.separator
                + aFile.name
                + "-"
                + UUID.randomUUID())
    )
    if (!theCLI.saveTemp) {
        tmp.deleteOnExit()
    }
    val out = PrintWriter(tmp)
    Demo01.LOGGER.finest("Demo01" + " tmp = |" + tmp.name + "|")
    var inLine: String? = ""
    var addSplat = false
    while ((src.readLine().also { inLine = it }) != null) {
        val newLine = StringBuilder(inLine)
        val onThisLine = java.util.ArrayList<Token>()
        var col72: Token? = null
        var cmBefore72: Token? = null
        var cmAfter72: Token? = null
        var cmFlag: Token? = null
        for (t: Token in tokens) {
            if (t.line == src.lineNumber) {
                onThisLine.add(t)
                if (t.type == JCLPPLexer.COMMENT_FLAG) {
                    cmFlag = t
                }
                if (t.type == JCLPPLexer.COMMENT_TEXT) {
                    if (t.text.trim { it <= ' ' }.isNotEmpty()) {
                        if (t.charPositionInLine < 71) {
                            cmBefore72 = t
                        } else {
                            cmAfter72 = t
                        }
                    }
                }
                if ((cmFlag == null) && (t.type == JCLPPLexer.COL_72) && (t.text.trim { it <= ' ' }.isNotEmpty())) {
                    /*
						Column 72 being non-blank on a line that begins with
						"// *" does not indicate a continuation of a comment.
						*/
                    col72 = t
                }
            }
        }
        if (addSplat) {
            /*
				Note that the splat is added to the line _after_ the column 72
				comment continuation was found.
				*/
            newLine.setCharAt(2, '*')
        }
        if (onThisLine.size > 0) {
            if (cmBefore72 != null && col72 != null) {
                /*
					Next line is a comment because this line has a comment
					_and_ a continuation indicator in column 72.
					*/
                addSplat = true
            } else {
                addSplat = false
            }
            if (cmAfter72 != null) {
                val start = cmAfter72.charPositionInLine
                val end = start + cmAfter72.text.length
                val spaces = String.format("%1$" + ((end - start) + 1) + "s", " ")
                newLine.replace(start, end, spaces)
            }
            if (col72 != null) {
                newLine.setCharAt(71, ' ')
            }
        }
        out.println(newLine.toString())
    }
    src.close()
    out.close()
    theCLI.setPosixAttributes(tmp)
    return tmp
}


/**
 * Create a directory to hold temporary files used in processing.
 */
@Throws(IOException::class)
fun newTempDir(theCLI: TheCLI): File {
    val tmpDir: File = Files.createTempDirectory("Demo01-").toFile()
    theCLI.setPosixAttributes(tmpDir)

    if (!theCLI.saveTemp) {
        tmpDir.deleteOnExit()
    }

    return tmpDir
}
